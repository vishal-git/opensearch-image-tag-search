{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c9e3e5-c859-4a7d-adc8-0cee57ff2f2a",
   "metadata": {},
   "source": [
    "In this notebook, we will set up OpenSearch and get it ready for search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded40cc-7357-48ef-81da-840f1e66ba67",
   "metadata": {},
   "source": [
    "Before you run code in this notebook, make sure that OpenSearch is running at `localhost:9200`. You can run the following command to fire up OpenSearch:\n",
    "\n",
    "```docker-compose up d```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57e219-658c-4bd0-9408-f53120b5f614",
   "metadata": {},
   "source": [
    "You can check whether OpenSearch is fired up or not using the following command: `curl -X GET \"http://localhost:9200\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0033843-cc1b-4694-8e0c-fa59a437cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3665158-19c6-470e-bcdf-e828ced50ff8",
   "metadata": {},
   "source": [
    "### Configure settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec555f82-2a58-45c4-8d68-6d93f1d13e3f",
   "metadata": {},
   "source": [
    "We will configure ML plug-ins, which let us use ML models::\n",
    "\n",
    "1. Set `only_run_on_ml_node` to `false`. This means that the ML models will run on the same node that holds the indexed data. (In production, we should set this to `true` so that ML models can run on their dedicated node.\n",
    "2. Set `model_access_control_enabled` to `true`. This will help us upload a custom ML model (if needed) instead of using ML models that are available within OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bc00bd-b49a-4b1f-8213-1940c896df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'persistent': {'plugins': {'ml_commons': {'only_run_on_ml_node': 'false',\n",
       "    'model_access_control_enabled': 'true',\n",
       "    'native_memory_threshold': '99'}}},\n",
       " 'transient': {}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://localhost:9200/_cluster/settings\"\n",
    "\n",
    "payload = {\n",
    "    \"persistent\": {\n",
    "        \"plugins\": {\n",
    "            \"ml_commons.only_run_on_ml_node\": \"false\",\n",
    "            \"ml_commons.model_access_control_enabled\": \"true\",\n",
    "            \"ml_commons.native_memory_threshold\": \"99\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.put(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e303a-5eb4-47b2-b310-4ee2bd5e0d0b",
   "metadata": {},
   "source": [
    "### Register a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674ca2f-2c7b-417a-b14b-87e7c304828b",
   "metadata": {},
   "source": [
    "Before we can assign (and use) a model, we need to create a **model group** so we can keep the models organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080adcbe-490c-4a40-984c-6efef29383a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_group_id': 'BdlFZZQBuL5CuRNm9qxV', 'status': 'CREATED'}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:9200/_plugins/_ml/model_groups/_register\"\n",
    "\n",
    "payload = {\n",
    "    \"name\": \"TEXT_model_group\",\n",
    "    \"description\": \"A model group for text embeddings.\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4d0fc3-ac2d-4fef-9c81-0caf35940f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a Model Group ID: BdlFZZQBuL5CuRNm9qxV\n"
     ]
    }
   ],
   "source": [
    "model_group_id = response.json()['model_group_id']\n",
    "\n",
    "print(f\"Created a Model Group ID: {model_group_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c8929-0523-45d3-9419-859c06cd785f",
   "metadata": {},
   "source": [
    "#### Register a model to the model group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc042ac7-0de6-406f-a7a5-f7329a8648e2",
   "metadata": {},
   "source": [
    "For this exercise, we will use `all-MiniLM-L6-v2` that's available on OpenSearch. See the list of all available models [here](https://opensearch.org/docs/latest/ml-commons-plugin/pretrained-models#supported-pretrained-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b942a03-d63e-43ef-a456-7458370aa4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_id': 'B9lMZZQBuL5CuRNm0qxb', 'status': 'CREATED'}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:9200/_plugins/_ml/models/_register\"\n",
    "\n",
    "payload = {\n",
    "    \"name\": \"huggingface/sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"version\": \"1.0.1\",\n",
    "    \"model_group_id\": model_group_id,\n",
    "    \"model_format\": \"TORCH_SCRIPT\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124316e8-a0b6-42db-bc02-9a40295110cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: B9lMZZQBuL5CuRNm0qxb\n"
     ]
    }
   ],
   "source": [
    "task_id = response.json()['task_id']\n",
    "\n",
    "print(f\"Task ID: {task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b136db-43cc-4594-b628-c50d7c6abac9",
   "metadata": {},
   "source": [
    "#### Check the status of the registered model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b7d46-e7a9-4954-98ae-b72c926a3113",
   "metadata": {},
   "source": [
    "Sometimes, registering a model may take some time (especially if the model is large). Let's make sure it's complete before we proceed to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ea08ca-4cd4-49e2-be2d-68534a001c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COMPLETED'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"http://localhost:9200/_plugins/_ml/tasks/{task_id}\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.json()['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c7145-3917-46e6-86ad-6ad221e49a94",
   "metadata": {},
   "source": [
    "If you don't see this status as 'COMPLETE' wait for some time. If you continue to get 'FAILED' status, check the docker logs using the following command: `docker logs opensearch_evals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80ef884-0c8f-480b-9ada-423257e2ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Model ID CNlMZZQBuL5CuRNm06zQ\n"
     ]
    }
   ],
   "source": [
    "model_id = response.json()['model_id']\n",
    "\n",
    "print(f\"Created Model ID {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d1f67-a3d1-4898-8c20-496e66356ede",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7a6049-5bdf-4431-b27d-08fbedf4d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_id': 'CtlNZZQBuL5CuRNm6qwG', 'task_type': 'DEPLOY_MODEL', 'status': 'CREATED'}\n"
     ]
    }
   ],
   "source": [
    "url = f\"http://localhost:9200/_plugins/_ml/models/{model_id}/_deploy\"\n",
    "\n",
    "response = requests.post(url, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "023b35a2-18c7-4faa-85aa-43e5042a4f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy Model Task ID CtlNZZQBuL5CuRNm6qwG\n"
     ]
    }
   ],
   "source": [
    "deploy_model_task_id = response.json()['task_id']\n",
    "\n",
    "print(f\"Deploy Model Task ID {deploy_model_task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9637e-eaec-464e-856a-48e559e3805a",
   "metadata": {},
   "source": [
    "#### Check the status of the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dcd698b-08f7-4c37-a9cb-10931536ea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': 'CNlMZZQBuL5CuRNm06zQ', 'task_type': 'DEPLOY_MODEL', 'function_name': 'TEXT_EMBEDDING', 'state': 'COMPLETED', 'worker_node': ['lFDMCo6MRD2f0WplTf_BrQ'], 'create_time': 1736866392582, 'last_update_time': 1736866392607, 'is_async': True}\n"
     ]
    }
   ],
   "source": [
    "url = f\"http://localhost:9200/_plugins/_ml/tasks/{deploy_model_task_id}\"\n",
    "\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af43ea-af8d-4a92-8c41-bd4db9a5fdda",
   "metadata": {},
   "source": [
    "Let's see if we can use this model to generate sentence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52057e01-2282-4413-a6f7-3d757fa4b656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_results': [{'output': [{'name': 'sentence_embedding', 'data_type': 'FLOAT32', 'shape': [384], 'data': [0.015552435, 0.07408792, -0.056174736, 0.020090407, -0.08067822, -0.023988575, 0.038808424, 0.03269541, -0.0018481113, -0.028275384, 0.06459784, -0.039391752, 0.007533904, 0.011672242, -0.025374359, -0.012356011, -0.024540061, -0.094170876, -0.046924755, -0.0017848986, 0.03356117, 0.059485007, -0.058551002, 0.010995594, 0.0643761, 0.03311312, -0.02322506, 0.033511985, 0.0556194, -0.0043963925, 0.00041493264, 0.014317813, 0.017027754, 0.03436633, 0.05863846, 0.028501928, -0.017333908, -0.0033512053, 0.048525553, 0.0031814873, 0.025857659, -0.11040843, 0.021466155, 0.03526723, -0.017158495, 0.04018047, -0.058251813, 0.046199523, -0.014536076, -0.052641265, 0.04867339, -0.03086721, -0.09876064, -0.023367776, 0.045699462, 0.0438746, 0.013673885, -0.014007184, 0.027587453, 0.064072855, 0.022105912, -0.0238617, -0.04212197, 0.059888072, 0.07783545, -0.045667414, 0.0029138038, -0.067083396, -0.030995166, -0.07300441, -0.060304362, 0.007639464, -0.002041031, 0.103761785, 0.028888946, 0.057743147, 0.0021422838, -0.09088995, 0.10777005, 0.06680119, -0.052286167, -0.09856073, -0.02395155, 0.03937866, 0.017873649, 0.088304274, 0.038061105, 0.032584354, -0.025689468, 0.032328617, -0.035166234, -0.034637284, -0.007827522, 0.012327439, -0.046576407, 0.034944348, -0.036452867, -0.0020309386, -0.028617598, 0.08694725, 0.0016206458, 0.01114891, 0.05589371, -0.010536419, -0.12986761, -0.033656947, 0.085809134, -0.047491472, 0.077587575, -0.045758642, -0.039180372, -0.013147978, 0.02362038, 9.493183e-05, -0.0611385, -0.053661548, -0.07537407, 0.04396831, -0.00061906525, 0.08708626, 0.08572149, -0.027355516, -0.07214939, -0.004891588, -0.06376829, -0.015506617, 0.054544665, -7.0987105e-33, -0.013178861, 0.016695442, 0.0736268, 0.00041744587, -0.024766777, -0.013036738, -0.11764427, 0.067558795, -0.0060976082, -0.014728465, -0.015715437, -0.06721384, 0.05591206, -0.033432186, 0.024967587, 0.023362905, 0.03883925, 0.057829265, -0.027006783, 0.0080983965, -0.0070970044, 0.035584748, 0.013815753, -0.11348792, -0.07462426, -0.07248475, -0.0062561384, -0.045225617, 0.057983164, 0.018278431, -0.027060235, -0.05782942, -0.05992272, 0.063604094, 0.062364303, 0.010123886, 0.04441214, -0.019856444, -0.017308312, 0.036532655, -0.050504338, -0.066956945, 0.028984468, 0.06355938, 0.06814863, -0.04353245, -0.027208522, -0.022882244, -0.012989684, 0.015384905, 0.0041004764, 0.044520874, 0.05516466, 0.028535897, 0.0075329943, 0.03293649, 0.05432473, -0.01107185, -0.07959874, 0.063641496, -0.04926777, 0.06054711, 0.012652149, 0.055660788, -0.041314103, 0.0026382376, -0.0026460574, -0.0895348, 0.055997632, 0.07566591, -0.029299926, -0.018406661, -0.03841257, 0.03273076, -0.05554805, -0.08379019, -0.016469624, 0.050316602, 0.013800079, -0.049480055, -0.01573503, -0.10153587, 0.012309884, -0.0053812456, -0.0472725, -0.016537238, -0.027840115, -0.12873936, 0.02837716, -0.08204776, -0.019904053, -0.019310404, -0.086881906, -0.043540176, 0.10086218, 4.3096216e-33, 0.0072596357, 0.07964377, -0.061448306, 0.08200618, 0.07396554, -0.03719135, 0.103087656, 0.01282098, -0.07596037, 0.061078504, 0.05263207, 0.017035097, -0.023329547, -0.017712334, 0.06645465, 0.03298458, -0.029243365, -0.009471591, 0.031531163, -0.023361193, -0.03274451, 0.09941356, 0.0014210776, 0.035598002, -0.056508563, 0.04081921, 0.059356056, -0.08012983, 0.012724033, 0.048589975, -0.023816107, -0.0043242113, -0.0018486826, 0.056072537, -0.054425076, -0.013546626, 0.16128817, -0.036310274, 0.0063590957, -0.0041402364, 0.03718502, 0.09587423, 0.08332266, 0.074213654, -0.029933907, 0.041666288, 0.047775466, -0.038901784, 0.018724592, 0.028608073, 0.00013337466, -0.048863612, 0.0077313944, 0.030457206, -0.03761528, 0.059036512, -0.13577867, 0.021813931, -0.04154411, 0.02483519, -0.07457747, 0.04460516, 0.04231665, 0.023195915, 0.0016538571, -0.061170217, -0.0339535, 0.005583008, -0.008500263, -0.09031296, 0.10107218, 0.012444928, -0.098455384, -0.042289797, -0.01947213, -0.075226165, -0.016758233, -0.029115234, 0.0043980754, 0.06002942, 0.01993842, -0.01073372, -0.017550554, 0.041297406, -0.013522106, -0.033716902, 0.0081634205, 0.11421508, -0.050838396, 0.04141273, 0.016555885, 0.07790922, -0.028356425, 0.020798007, 0.00023347314, -1.6703778e-08, -0.0005567441, -0.032366935, -0.056428913, -0.019109573, -0.0010358307, 0.069651194, -0.012561871, -0.13785392, -0.0056796703, -0.031705752, 0.021008838, 0.009887943, -0.08527105, -0.029408226, 0.027811358, -0.03869859, -0.054390993, -0.033087526, -0.02447963, 0.05002815, -0.042919267, 0.033781745, -0.005776902, -0.034412477, -0.04996205, 0.068129785, -0.0077821207, 0.113090105, -0.0023172512, 0.009452486, 0.11175238, 0.09625973, -0.039931923, -0.083468124, -0.059006978, 0.109285176, 0.026692977, 0.023142856, 0.0725204, 0.054992147, -0.02481732, 0.02674983, -0.02246118, 0.03964597, -0.0244615, -0.066336416, -0.007657877, -0.048915677, -0.020176202, -0.10789288, -0.009620416, -0.0035146908, 0.01626798, -0.017380819, -0.02055579, -0.027130751, -0.012375868, 0.00058644125, -0.10653359, 0.07693488, 0.08848152, 0.022332402, 0.10382052, -0.03453348]}]}]}\n"
     ]
    }
   ],
   "source": [
    "url = f\"http://localhost:9200/_plugins/_ml/_predict/text_embedding/{model_id}\"\n",
    "\n",
    "payload = {\n",
    "    \"text_docs\":[\"This is a test string.\"],\n",
    "    \"return_number\": True,\n",
    "    \"target_response\": [\"sentence_embedding\"]\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb950d5-2ef0-4526-b042-b37049a840d1",
   "metadata": {},
   "source": [
    "Great, that worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd48642-bcc5-49bc-98c8-aada48786fa4",
   "metadata": {},
   "source": [
    "### Create an ingestion pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ca518-68cb-43cd-abce-54a650f7ec12",
   "metadata": {},
   "source": [
    "We want to use the `tags` column in our dataset (which was created in the previous notebook), and generate embeddings using the strings in that column. We will store those embeddings into the `tag_embedding` column in the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94cb7821-14df-4f12-ae94-2893cd658d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:9200/_ingest/pipeline/tags-ingest-pipeline\"\n",
    "\n",
    "payload = {\n",
    "    \"description\": \"Image tags embedding pipeline\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": model_id,\n",
    "                \"field_map\": {\n",
    "                    \"tags\": \"tag_embedding\"  # input column -> vector db column\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.put(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c1fcb-4a5a-4e7a-9a71-25f349d05bef",
   "metadata": {},
   "source": [
    "Now that we have configured OpenSearch, registered a model, and created an ingestion pipeline, we are ready to ingest the dataset that we created in the previous notebook. Let's [move on to the next notebook](./02_index_tags_data.ipynb)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
